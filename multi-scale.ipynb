{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e61ef2d8-f315-4f7f-b07e-1de0f4e8441a",
    "_uuid": "1677fddbb95f7545b6540e9201f3339a0fdbfc5d"
   },
   "source": [
    "# Intro\n",
    "Hello! This rather quick and dirty kernel shows how to get started on segmenting nuclei using a neural network in Keras. \n",
    "\n",
    "The architecture used is the so-called [U-Net](https://arxiv.org/abs/1505.04597), which is very common for image segmentation problems such as this. I believe they also have a tendency to work quite well even on small datasets.\n",
    "\n",
    "Let's get started importing everything we need!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "c332549b-8d23-4bb5-8497-e7a8eb8b21d2",
    "_uuid": "5c38504af3a84bee68c66d3cde74443c58df422f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hdd/home/peter0749/virtualenv/tf_keras/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/hdd/home/peter0749/virtualenv/tf_keras/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "# Set some parameters\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 3\n",
    "TRAIN_PATH = '/hdd/dataset/nuclei_dataset/stage1_train/'\n",
    "TEST_PATH = '/hdd/dataset/nuclei_dataset/stage1_test/'\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "ffa0caf0-2d1b-40f2-865b-8e6db88526b6",
    "_uuid": "3fb9d6530fbbd0e22e41fc4fd9fd9fc0bff027ac"
   },
   "outputs": [],
   "source": [
    "# Get train and test IDs\n",
    "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
    "test_ids = next(os.walk(TEST_PATH))[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "59c4a25d-645f-4b74-9c53-145ac78cc481",
    "_uuid": "875af74f980236825de3a650825b46e25632422c"
   },
   "source": [
    "# Get the data\n",
    "Let's first import all the images and associated masks. I downsample both the training and test images to keep things light and manageable, but we need to keep a record of the original sizes of the test images to upsample our predicted masks and create correct run-length encodings later on. There are definitely better ways to handle this, but it works fine for now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "ca0cc34b-c26f-41ee-88d7-975aebdb634e",
    "_uuid": "9e389ba8bdb5b6fc03b231b6a6c84a8bde634053"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting train images and masks ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/670 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b073c22d129b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmask_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/masks/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mmask_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/masks/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmask_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mdt_\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mndi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance_transform_edt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mcY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munravel_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# find local maximum of edt image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenv/tf_keras/lib/python3.6/site-packages/scipy/ndimage/morphology.py\u001b[0m in \u001b[0;36mdistance_transform_edt\u001b[0;34m(input, sampling, return_distances, return_indices, distances, indices)\u001b[0m\n\u001b[1;32m   2134\u001b[0m                             dtype=numpy.int32)\n\u001b[1;32m   2135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2136\u001b[0;31m     \u001b[0m_nd_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meuclidean_feature_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2137\u001b[0m     \u001b[0;31m# if requested, calculate the distance transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_distances\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from skimage.draw import circle\n",
    "import math\n",
    "\n",
    "# Get and resize train images and masks\n",
    "X_train = []\n",
    "Y_train = [] \n",
    "\n",
    "print('Getting train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = TRAIN_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "    X_train.append(img)\n",
    "    mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
    "    mark = np.zeros(img.shape[:2], dtype=np.float32)\n",
    "    dt   = np.zeros(img.shape[:2], dtype=np.float32)\n",
    "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "        mask_ = (imread(path + '/masks/' + mask_file)>0).astype(np.float32)\n",
    "        dt_   = ndi.distance_transform_edt(mask_).astype(np.float32)\n",
    "        r = max( img.shape[0], img.shape[1] ) * .01\n",
    "        cY, cX = np.unravel_index(np.argmax(dt_, axis=None), dt_.shape) # find local maximum of edt image\n",
    "        cY = np.clip(cY, r, img.shape[0]-r)\n",
    "        cX = np.clip(cX, r, img.shape[1]-r)\n",
    "        # dt_   = dt_ - np.min(dt_)\n",
    "        dt_   = dt_ / np.max(dt_) # get a distance transform of an instance\n",
    "        dt    = np.maximum(dt, dt_)\n",
    "        rr, cc = circle(cY, cX, r, shape=img.shape[:2])\n",
    "        mark[rr,cc] = 1\n",
    "        mask = np.maximum(mask, mask_)\n",
    "    Y_train.append([mask, mark, dt])\n",
    "\n",
    "# Get and resize test images\n",
    "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "print('Getting and resizing test images ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = TEST_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "    sizes_test.append(img.shape[:2])\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_test[n] = img\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c0523b03-1fc5-4505-a1b8-eb35ee617c8a",
    "_uuid": "d4f8327802a1ec6139ce0585953986272ba62ce1"
   },
   "source": [
    "Let's see if things look all right by drawing some random images and their associated masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "88829b53-50ce-45d9-9540-77dd7384ad4c",
    "_uuid": "283af26f0860b7069bdfd133c746e5d20971542c"
   },
   "outputs": [],
   "source": [
    "# Check if training data looks all right\n",
    "ix = random.randint(0, len(train_ids)-1)\n",
    "plt.imshow(X_train[ix])\n",
    "plt.show()\n",
    "plt.imshow(np.squeeze(Y_train[ix][0]), cmap='gray')\n",
    "plt.show()\n",
    "x_copy = X_train[ix].copy()\n",
    "x_copy[np.squeeze(Y_train[ix][1])>0, :] = 255, 0, 0\n",
    "plt.imshow(x_copy)\n",
    "plt.show()\n",
    "plt.imshow(np.squeeze(Y_train[ix][2]), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2574ffe9-b911-4bfd-a00f-9ba5c25f45de",
    "_uuid": "938648da705689a0f940ff462477c801db3f0737"
   },
   "source": [
    "Seems good!\n",
    "\n",
    "# Create our Keras metric\n",
    "\n",
    "Now we try to define the *mean average precision at different intersection over union (IoU) thresholds* metric in Keras. TensorFlow has a mean IoU metric, but it doesn't have any native support for the mean over multiple thresholds, so I tried to implement this. **I'm by no means certain that this implementation is correct, though!** Any assistance in verifying this would be most welcome! \n",
    "\n",
    "*Update: This implementation is most definitely not correct due to the very large discrepancy between the results reported here and the LB results. It also seems to just increase over time no matter what when you train ... *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c1df6f3a-d58f-434b-9216-ef7be38637d4",
    "_uuid": "5abd38950ae99b60f8afec7656eb654a48d449fe"
   },
   "outputs": [],
   "source": [
    "from keras.losses import mean_squared_error\n",
    "# Define IoU metric\n",
    "def mean_iou(y_true_, y_pred_):\n",
    "    y_true = y_true_[...,0]\n",
    "    y_pred = y_pred_[...,0]\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=None) # scaler\n",
    "\n",
    "def mean_iou_marker(y_true_, y_pred_):\n",
    "    y_true = y_true_[...,1]\n",
    "    y_pred = y_pred_[...,1]\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=None) # scaler\n",
    "\n",
    "def custom_loss(y_true_, y_pred_):\n",
    "    \n",
    "    def dice_coef(y_true, y_pred, intersection): # (batch_size, h, w)\n",
    "        sum_intersection = K.sum(intersection)\n",
    "        return (2.*sum_intersection + K.epsilon()) / (K.sum(y_true) + K.sum(y_pred) + sum_intersection + K.epsilon()) # scaler\n",
    "    \n",
    "    obj_scale = 5\n",
    "    \n",
    "    y_true_hm = y_true_[...,0] # (batch_size, h, w)\n",
    "    y_true_mk = y_true_[...,1] # (batch_size, h, w)\n",
    "    y_true_dt = y_true_[...,2] # (batch_size, h, w)\n",
    "    \n",
    "    y_pred_hm = y_pred_[...,0] # (batch_size, h, w)\n",
    "    y_pred_mk = y_pred_[...,1] # (batch_size, h, w)\n",
    "    y_pred_dt = y_pred_[...,2] # (batch_size, h, w)\n",
    "    \n",
    "    true_mask_scale = y_true_hm * obj_scale\n",
    "    s_dt_regression_loss = K.sum(K.abs(y_true_dt - y_pred_dt) * true_mask_scale, axis=None) / (K.sum(true_mask_scale, axis=None) + K.epsilon()) # scaler\n",
    "    \n",
    "    intersection_scale =  (1 - y_true_dt) * y_true_hm + 1\n",
    "    \n",
    "    mk_intersection = y_true_mk * y_pred_mk\n",
    "    hm_intersection = y_true_hm * y_pred_hm\n",
    "    \n",
    "    s_marker_dice_coef = dice_coef(y_true_mk * intersection_scale, y_pred_mk * intersection_scale, mk_intersection * intersection_scale) # scaler\n",
    "    s_heatmap_dice_coef= dice_coef(y_true_hm * intersection_scale, y_pred_hm * intersection_scale, hm_intersection * intersection_scale) # scaler\n",
    "    s_marker_entropy   = K.sum(K.binary_crossentropy(y_true_mk, y_pred_mk) * intersection_scale, axis=None) / (K.sum(intersection_scale, axis=None) + K.epsilon()) # scaler\n",
    "    s_heatmap_entropy  = K.sum(K.binary_crossentropy(y_true_hm, y_pred_hm) * intersection_scale, axis=None) / (K.sum(intersection_scale, axis=None) + K.epsilon()) # scaler\n",
    "    s_marker_loss = .5 * s_marker_entropy - s_marker_dice_coef + 1. # scaler [0, inf)\n",
    "    s_heatmap_loss= .5 * s_heatmap_entropy - s_heatmap_dice_coef + 1. # scaler [0, inf)\n",
    "    \n",
    "    loss = s_marker_loss + s_heatmap_loss + s_dt_regression_loss # scaler [0, inf)\n",
    "    loss = tf.Print(loss, [s_marker_dice_coef], message='\\nMarker DC:\\t', summarize=10)\n",
    "    loss = tf.Print(loss, [s_marker_entropy], message='\\nMarker ET:\\t', summarize=10)\n",
    "    loss = tf.Print(loss, [s_heatmap_dice_coef], message='\\nHeatmap DC:\\t', summarize=10)\n",
    "    loss = tf.Print(loss, [s_heatmap_entropy], message='\\nHeatmap ET:\\t', summarize=10)\n",
    "    loss = tf.Print(loss, [s_dt_regression_loss], message='\\nDT MAE:\\t', summarize=10)\n",
    "    \n",
    "    return loss # scaler [0, inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c3b9f148-1dba-4b6a-981b-6cdbf394fc3c",
    "_uuid": "986488a4c5223576be370e224426a30431911eb2"
   },
   "source": [
    "# Build and train our neural network\n",
    "Next we build our U-Net model, loosely based on [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/pdf/1505.04597.pdf) and very similar to [this repo](https://github.com/jocicmarko/ultrasound-nerve-segmentation) from the Kaggle Ultrasound Nerve Segmentation competition.\n",
    "\n",
    "![](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c1dbc57c-b497-4ccb-b077-2053203ab7ed",
    "_uuid": "0aa97d66c29f45dfac9b0f45fcf74ba0e778ba5d"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Lambda, Add, Activation, UpSampling2D, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def build_stage(inputs, last=None, id_='st1'):\n",
    "    def conv(f, k=3, act='elu'):\n",
    "        return Conv2D(f, (k, k), activation=act, kernel_initializer='he_normal', padding='same')\n",
    "    def _incept_conv(inputs, f, dropout=0, chs=[0.15, 0.5, 0.25, 0.1]):\n",
    "        fs = [] # determine channel number\n",
    "        for k in chs:\n",
    "            t = max(int(k*f), 1) # at least 1 channel\n",
    "            fs.append(t)\n",
    "        \n",
    "        fs[1] += f-np.sum(fs) # reminding channels allocate to 3x3 conv\n",
    "        \n",
    "        c1x1 = conv(fs[0], 1, act='linear') (inputs)\n",
    "        c3x3 = conv(max(1, fs[1]//2), 1, act='elu') (inputs)\n",
    "        c5x5 = conv(max(1, fs[2]//2), 1, act='elu') (inputs)\n",
    "        cpool= MaxPooling2D(pool_size=(3, 3), strides=(1, 1), padding='same') (inputs)\n",
    "        \n",
    "        c3x3 = conv(fs[1], 3, act='linear') (c3x3)\n",
    "        c5x5 = conv(fs[2], 5, act='linear') (c5x5)\n",
    "        cpool= conv(fs[3], 1, act='linear') (cpool)\n",
    "        \n",
    "        output = concatenate([c1x1, c3x3, c5x5, cpool], axis=-1)\n",
    "        if dropout>0:\n",
    "            output = Dropout(dropout) (output)\n",
    "        return output\n",
    "    \n",
    "    def _res_conv(inputs, f, k=3, dropout=0.1): # very simple residual module\n",
    "        channels = int(inputs.shape[-1])\n",
    "        \n",
    "        cs = _incept_conv(inputs, f, dropout=dropout)\n",
    "        \n",
    "        if f!=channels:\n",
    "            t1 = conv(f, 1, 'linear') (inputs) # identity mapping\n",
    "        else:\n",
    "            t1 = inputs\n",
    "        \n",
    "        out = Add()([t1, cs]) # t1 + c2\n",
    "        out = Activation('elu') (out)\n",
    "        return out\n",
    "    def pool():\n",
    "        return MaxPooling2D((2, 2))\n",
    "    def up(inputs, dropout=0):\n",
    "        upsampled = Conv2DTranspose(int(inputs.shape[-1]), (2, 2), strides=(2, 2), padding='same') (inputs)\n",
    "        if dropout>0:\n",
    "            upsampled = Dropout(dropout) (upsampled)\n",
    "        return upsampled\n",
    "    \n",
    "    if last is None:\n",
    "        c1 = Lambda(lambda x: x / 255) (inputs) # 1st stage input, an image\n",
    "    else:\n",
    "        c1 = concatenate()([inputs, last])\n",
    "    \n",
    "    c1 = _res_conv(c1, 32, 3)\n",
    "    c1 = _res_conv(c1, 32, 3)\n",
    "    o1 = c1\n",
    "    p1 = pool() (c1)\n",
    "    \n",
    "    c2 = _res_conv(p1, 64, 3)\n",
    "    c2 = _res_conv(c2, 64, 3)\n",
    "    p2 = pool() (c2)\n",
    "\n",
    "    c3 = _res_conv(p2, 128, 3)\n",
    "    c3 = _res_conv(c3, 128, 3)\n",
    "    p3 = pool() (c3)\n",
    "    \n",
    "    c4 = _res_conv(p3, 256, 3)\n",
    "    c4 = _res_conv(c4, 256, 3)\n",
    "    p4 = pool() (c4)\n",
    "    \n",
    "    c5 = _res_conv(p4, 512, 3)\n",
    "    c5 = _res_conv(c5, 512, 3)\n",
    "    p5 = pool() (c5)\n",
    "    \n",
    "    c6 = _res_conv(p5, 512, 3)\n",
    "    c6 = _res_conv(c6, 512, 3)\n",
    "    \n",
    "    u7 = up (c6)\n",
    "    c7 = concatenate([u7, c5])\n",
    "    c7 = _res_conv(c7, 512, 3)\n",
    "    c7 = _res_conv(c7, 512, 3)\n",
    "    \n",
    "    u8 = up (c7)\n",
    "    c8 = concatenate([u8, c4])\n",
    "    c8 = _res_conv(c8, 256, 3)\n",
    "    c8 = _res_conv(c8, 256, 3)\n",
    "    \n",
    "    u9 = up (c8)\n",
    "    c9 = concatenate([u9, c3])\n",
    "    c9 = _res_conv(c9, 128, 3)\n",
    "    c9 = _res_conv(c9, 128, 3)\n",
    "    \n",
    "    u10 = up (c9)\n",
    "    c10 = concatenate([u10, c2])\n",
    "    c10 = _res_conv(c10, 64, 3)\n",
    "    c10 = _res_conv(c10, 64, 3)\n",
    "    \n",
    "    u11 = up (c10)\n",
    "    c11 = concatenate([u11, c1])\n",
    "    c11 = _res_conv(c11, 32, 3)\n",
    "    c11 = _res_conv(c11, 32, 3)\n",
    "    \n",
    "    outputs = Conv2D(3, (1, 1), activation='sigmoid', name=id_+'_out') (c11)\n",
    "    return outputs, o1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "from skimage.transform import AffineTransform, warp\n",
    "import copy\n",
    "\n",
    "class data_generator(Sequence):\n",
    "    def __init__(self, IMG_WIDTH, IMG_HEIGHT, data, label, batch_size=4, training=True):\n",
    "        self.data = data\n",
    "        self.label= label\n",
    "        self.batch_size = batch_size\n",
    "        self.training = training\n",
    "        self.IMG_WIDTH = IMG_WIDTH\n",
    "        self.IMG_HEIGHT= IMG_HEIGHT\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(float(len(self.data))/self.batch_size))\n",
    "    def on_epoch_end(self):\n",
    "        if self.training: self.data, self.label = shuffle(self.data, self.label)\n",
    "    def __getitem__(self, i):\n",
    "        l_bound =  i    * self.batch_size\n",
    "        r_bound = (i+1) * self.batch_size\n",
    "        if r_bound>len(self.data): # ensure every iteration has the same batch size\n",
    "            r_bound = len(self.data)\n",
    "            l_bound = r_bound - self.batch_size\n",
    "        dat_que = np.empty((self.batch_size, self.IMG_HEIGHT, self.IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "        lab_que = np.empty((self.batch_size, self.IMG_HEIGHT, self.IMG_WIDTH, 3), dtype=np.float32)\n",
    "        for n, index in enumerate(range(l_bound, r_bound)):\n",
    "            img = copy.deepcopy(self.data[index]).astype(np.float32) / 255.\n",
    "            lab = copy.deepcopy(self.label[index][0])\n",
    "            marker = copy.deepcopy(self.label[index][1])\n",
    "            dt = copy.deepcopy(self.label[index][2])\n",
    "            if self.training:\n",
    "                if np.random.rand() < .5: # flip vertical\n",
    "                    img = np.flip(img, 0)\n",
    "                    lab = np.flip(lab, 0)\n",
    "                    marker = np.flip(marker, 0)\n",
    "                    dt = np.flip(dt, 0)\n",
    "                if np.random.rand() < .5: # flip horizontal\n",
    "                    img = np.flip(img, 1)\n",
    "                    lab = np.flip(lab, 1)\n",
    "                    marker = np.flip(marker, 1)\n",
    "                    dt = np.flip(dt, 1)\n",
    "\n",
    "                # rotation, shearing\n",
    "                if np.random.rand() < 0.5:\n",
    "                    y, x, _ = img.shape\n",
    "                    h, w = y, x\n",
    "                    img = np.pad(img, ((y//2, y//2), (x//2, x//2), (0, 0)), 'reflect')\n",
    "                    lab = np.pad(lab, ((y//2, y//2), (x//2, x//2)), 'reflect')\n",
    "                    marker = np.pad(marker, ((y//2, y//2), (x//2, x//2)), 'reflect')\n",
    "                    dt = np.pad(dt, ((y//2, y//2), (x//2, x//2)), 'reflect')\n",
    "                    \n",
    "                    rotT = np.random.uniform(-45,45)\n",
    "                    shearT = np.random.uniform(-5,5)\n",
    "                    translationX = np.random.uniform(-w,w) * .1\n",
    "                    translationY = np.random.uniform(-h,h) * .1\n",
    "                    atmtx = AffineTransform(rotation=rotT, shear=shearT, translation=(translationX, translationY))\n",
    "\n",
    "                    img = warp(img, atmtx)\n",
    "                    lab = warp(lab, atmtx)\n",
    "                    marker = warp(marker, atmtx)\n",
    "                    dt = warp(dt, atmtx)\n",
    "\n",
    "                    img = img[h//2:h//2+h,w//2:w//2+w,:]\n",
    "                    lab = lab[h//2:h//2+h,w//2:w//2+w]\n",
    "                    marker = marker[h//2:h//2+h,w//2:w//2+w]\n",
    "                    dt = dt[h//2:h//2+h,w//2:w//2+w]\n",
    "\n",
    "                # random amplify each channel\n",
    "                a = .1 # amptitude\n",
    "                t  = [np.random.uniform(-a,a)]\n",
    "                t += [np.random.uniform(-a,a)]\n",
    "                t += [np.random.uniform(-a,a)]\n",
    "                t = np.array(t)\n",
    "\n",
    "                img = np.clip(img * (1. + t), 0, 1) # channel wise amplify\n",
    "                up = np.random.uniform(0.95, 1.05) # change gamma\n",
    "                img = np.clip(img**up, 0, 1) # apply gamma and convert back to range [0,255]\n",
    "\n",
    "            ### end of data augmentation ###\n",
    "\n",
    "            img = (resize(img, (self.IMG_HEIGHT, self.IMG_WIDTH), mode='constant', preserve_range=True)*255.).astype(np.uint8)\n",
    "            lab = resize(lab, (self.IMG_HEIGHT, self.IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "            marker = resize(marker, (self.IMG_HEIGHT, self.IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "            dt = resize(dt, (self.IMG_HEIGHT, self.IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "\n",
    "            dat_que[n,:,:,:] = img\n",
    "            lab_que[n,:,:,0] = lab > .5\n",
    "            lab_que[n,:,:,1] = marker > .5\n",
    "            lab_que[n,:,:,2] = dt\n",
    "        return dat_que, lab_que"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9415b1c4-aa69-41b9-a1e3-d6053dbd4f64",
    "_uuid": "c060db22daa2abf12b28240cd81bbcbf1ce1bf87"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "if not os.path.exists('./models'):\n",
    "    os.makedirs('./models')\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=65, shuffle=True)\n",
    "\n",
    "BS=6\n",
    "EPOCHS=1200\n",
    "CHRES_EPOCHS=10\n",
    "train_scales = [128,192,256,320,384]\n",
    "loss = []\n",
    "marker_miou = []\n",
    "seg_miou = []\n",
    "ite = 0\n",
    "\n",
    "checkpointer = ModelCheckpoint('./models/model.{epoch:03d}.vl.{val_loss:.2f}.vi.{val_mean_iou:.2f}.vim.{val_mean_iou_marker:.2f}.h5', verbose=0, save_best_only=False, save_weights_only=True)\n",
    "checkpointer_best = ModelCheckpoint('./models/best.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "while ite<EPOCHS:\n",
    "    steps = min(EPOCHS-ite, CHRES_EPOCHS)\n",
    "    scale = np.random.choice(train_scales)\n",
    "    print('Changing scale to %d x %d'%(scale, scale))\n",
    "    train_generator = data_generator(scale, scale, X_train, Y_train, batch_size=BS, training=True)\n",
    "    val_generator = data_generator(scale, scale, X_val, Y_val, batch_size=BS, training=False)\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    inputs = Input((scale, scale, IMG_CHANNELS))\n",
    "    out, _ = build_stage(inputs, None, 'st1')\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[out])\n",
    "    model.compile(loss=custom_loss, metrics=[mean_iou, mean_iou_marker], optimizer='adam')\n",
    "    \n",
    "    history = model.fit_generator(train_generator,\n",
    "                                  steps_per_epoch=len(train_generator), epochs=ite+steps, \n",
    "                                  validation_data=val_generator, \n",
    "                                  validation_steps=len(val_generator),\n",
    "                                  callbacks=[checkpointer, checkpointer_best],\n",
    "                                  workers=5,\n",
    "                                  use_multiprocessing=True,\n",
    "                                  initial_epoch=ite\n",
    "                                  )\n",
    "    seg_miou.extend(history.history['val_mean_iou'])\n",
    "    marker_miou.extend(history.history['val_mean_iou_marker'])\n",
    "    loss.extend(history.history['val_loss'])\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    ite += steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(seg_miou)\n",
    "plt.title('model mean_iou')\n",
    "plt.ylabel('val_mean_iou')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(marker_miou)\n",
    "plt.title('model mean_iou_marker')\n",
    "plt.ylabel('val_mean_iou_marker')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss)\n",
    "plt.title('val_model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1f381f5b-1b71-4daa-a417-e02f4894540b",
    "_uuid": "bb15226ea617cf91ed8f43179fccb5a15809e5a0"
   },
   "source": [
    "All right, looks good! Loss seems to be a bit erratic, though. I'll leave it to you to improve the model architecture and parameters! \n",
    "\n",
    "# Make predictions\n",
    "\n",
    "Let's make predictions both on the test set, the val set and the train set (as a sanity check). Remember to load the best saved model if you've used early stopping and checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2daa48d5-ac98-4e18-af3f-a582baaa44f0",
    "_uuid": "f841760b4abca1a25cb750822f88268bd79bf2ce"
   },
   "outputs": [],
   "source": [
    "from skimage.morphology import closing, square, remove_small_objects\n",
    "from skimage.segmentation import clear_border\n",
    "\n",
    "# Predict on train, val and test\n",
    "\n",
    "train_generator = data_generator(IMG_WIDTH, IMG_HEIGHT, X_train, Y_train, batch_size=BS, training=True)\n",
    "val_generator = data_generator(IMG_WIDTH, IMG_HEIGHT, X_val, Y_val, batch_size=BS, training=False)\n",
    "\n",
    "K.clear_session()\n",
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "out, _ = build_stage(inputs, None, 'st1')\n",
    "model = Model(inputs=[inputs], outputs=[out])\n",
    "model.compile(loss=custom_loss, metrics=[mean_iou, mean_iou_marker], optimizer='adam')\n",
    "\n",
    "model.load_weights('./models/best.h5')\n",
    "preds_train = model.predict_generator(train_generator, steps=len(train_generator), verbose=1)\n",
    "preds_val = model.predict_generator(val_generator, steps=len(val_generator), verbose=1)\n",
    "preds_test = model.predict(X_test, verbose=1, batch_size=BS)\n",
    "\n",
    "preds_train, preds_train_marker, preds_train_dt = np.transpose(preds_train, (3,0,1,2))\n",
    "preds_val, preds_val_marker, preds_val_dt = np.transpose(preds_val, (3,0,1,2))\n",
    "preds_test, preds_test_marker, preds_test_dt = np.transpose(preds_test, (3,0,1,2))\n",
    "\n",
    "# Threshold predictions\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
    "preds_train_marker_t = (preds_train_marker > 0.5).astype(np.uint8)\n",
    "preds_val_marker_t = (preds_val_marker > 0.5).astype(np.uint8)\n",
    "\n",
    "# Create list of upsampled test masks\n",
    "preds_test_upsampled = []\n",
    "for i in range(len(preds_test)):\n",
    "    preds_test_upsampled.append((resize(np.squeeze(preds_test[i]), \n",
    "                                       (sizes_test[i][0], sizes_test[i][1]), \n",
    "                                       mode='constant', preserve_range=True),\n",
    "                                 resize(np.squeeze(preds_test_marker[i]), \n",
    "                                       (sizes_test[i][0], sizes_test[i][1]), \n",
    "                                       mode='constant', preserve_range=True),\n",
    "                                 resize(np.squeeze(preds_test_dt[i]), \n",
    "                                       (sizes_test[i][0], sizes_test[i][1]), \n",
    "                                       mode='constant', preserve_range=True)\n",
    "                                ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "59a0af60-a7d7-41ef-a6fe-9e3c72defa07",
    "_uuid": "4f99c1bf852e82b60bd4f982ca0df293f712cdf0"
   },
   "outputs": [],
   "source": [
    "from skimage.morphology import watershed\n",
    "\n",
    "# Run-length encoding stolen from https://www.kaggle.com/rakhlin/fast-run-length-encoding-python\n",
    "def rle_encoding(x):\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "def lb(image, marker, distance):\n",
    "    if np.sum(image) < np.sum(marker):\n",
    "        image = marker\n",
    "    else:\n",
    "        marker = np.array((marker==1) & (image==1))\n",
    "    # distance = ndi.distance_transform_edt(image) # old one\n",
    "    markers = ndi.label(marker)[0]\n",
    "    labels = watershed(-distance, markers, mask=image)\n",
    "    if np.sum(labels) == 0:\n",
    "        labels[0,0] = 1\n",
    "    return labels\n",
    "\n",
    "def prob_to_rles(x, marker, dt, cutoff=0.5, cutoff_marker=0.5):\n",
    "    lab_img = lb(x > cutoff, marker > cutoff_marker, dt)\n",
    "    for i in range(1, lab_img.max() + 1):\n",
    "        yield rle_encoding(lab_img == i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "649248cd-a1fb-4da6-ade2-4bebad44bcab",
    "_uuid": "7e06242a50870e07a080064a4912b761775990fa"
   },
   "outputs": [],
   "source": [
    "# Perform a sanity check on some random training samples\n",
    "ix = random.randint(0, len(preds_train_t)-1)\n",
    "print(ix)\n",
    "shape = Y_train[ix][0].shape[:2]\n",
    "plt.imshow(X_train[ix])\n",
    "plt.show()\n",
    "plt.imshow(np.squeeze(Y_train[ix][0]))\n",
    "plt.show()\n",
    "plt.imshow(resize(np.squeeze(preds_train_t[ix]), shape))\n",
    "plt.show()\n",
    "plt.imshow(np.squeeze(Y_train[ix][1]))\n",
    "plt.show()\n",
    "plt.imshow(resize(np.squeeze(preds_train_marker_t[ix]), shape))\n",
    "plt.show()\n",
    "plt.imshow(resize(np.squeeze(preds_train_dt[ix]), shape), cmap='gray')\n",
    "plt.show()\n",
    "lab = lb(preds_train_t[ix], preds_train_marker_t[ix], preds_train_dt[ix])\n",
    "plt.imshow(lab, cmap=plt.get_cmap('tab20'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "af602aea-5e56-42a8-9331-54b4b2650593",
    "_uuid": "5fcee2b9aee2fba5c60d43ad48a14139e9c1318c"
   },
   "source": [
    "The model is at least able to fit to the training data! Certainly a lot of room for improvement even here, but a decent start. How about the validation data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4f66b75c-c694-41a1-8c91-34bb6595837b",
    "_uuid": "d4ccbb559375bc2777ffb692a20adc313159f2cc"
   },
   "outputs": [],
   "source": [
    "# Perform a sanity check on some random validation samples\n",
    "ix = random.randint(0, len(preds_val_t))\n",
    "print(ix)\n",
    "shape = Y_val[ix][0].shape[:2]\n",
    "plt.imshow(X_val[ix])\n",
    "plt.show()\n",
    "plt.imshow(np.squeeze(Y_val[ix][0]))\n",
    "plt.show()\n",
    "plt.imshow(resize(np.squeeze(preds_val_t[ix]), shape))\n",
    "plt.show()\n",
    "plt.imshow(np.squeeze(Y_val[ix][1]))\n",
    "plt.show()\n",
    "plt.imshow(resize(np.squeeze(preds_val_marker_t[ix]), shape))\n",
    "plt.show()\n",
    "plt.imshow(resize(np.squeeze(preds_val_dt[ix]), shape))\n",
    "plt.show()\n",
    "lab = lb(preds_val_t[ix], preds_val_marker_t[ix], preds_val_dt[ix])\n",
    "plt.imshow(lab, cmap=plt.get_cmap('tab20'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a6690535-b2e4-49ac-98d9-7191bfabfb6f",
    "_uuid": "6a34c98de7c6ae473f676a34fe7e099b46764eca"
   },
   "source": [
    "Not too shabby! Definitely needs some more training and tweaking.\n",
    "\n",
    "# Encode and submit our results\n",
    "\n",
    "Now it's time to submit our results. I've stolen [this](https://www.kaggle.com/rakhlin/fast-run-length-encoding-python) excellent implementation of run-length encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "31133f8c-3f40-4dff-8e1d-898d56672332",
    "_uuid": "2e07f6afc4787b068ba714428145dcb3951d718f"
   },
   "source": [
    "Let's iterate over the test IDs and generate run-length encodings for each seperate mask identified by skimage ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "22fe24a1-7659-4cc9-9d23-211f38e5b99f",
    "_uuid": "089587843ed6a3955fdcb9b23a6ec3bf5d703688"
   },
   "outputs": [],
   "source": [
    "new_test_ids = []\n",
    "rles = []\n",
    "for n, id_ in enumerate(test_ids):\n",
    "    rle = list(prob_to_rles(*preds_test_upsampled[n]))\n",
    "    rles.extend(rle)\n",
    "    new_test_ids.extend([id_] * len(rle))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "20b6b627-0fd6-425d-888f-da7f39efb124",
    "_uuid": "849184a40a2c9c21506d8b8eb10ad9155fa229e8"
   },
   "source": [
    "... and then finally create our submission!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1ba0ee3a-cca0-4349-83f6-09a1ac6fcb44",
    "_uuid": "ba589f56f5be1e6886bc88f5bf9e7d0a408e4048"
   },
   "outputs": [],
   "source": [
    "# Create submission DataFrame\n",
    "sub = pd.DataFrame()\n",
    "sub['ImageId'] = new_test_ids\n",
    "sub['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))\n",
    "sub.to_csv('sub-dsbowl2018-1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "222475b9-3171-461a-90f0-a820a6bd2634",
    "_uuid": "fb5e6f8cca872f1bd7036f6d9ac2ed2cab615536",
    "collapsed": true
   },
   "source": [
    "This scored 0.233 on the LB for me. That was with version 2 of this notebook; be aware that the results from the neural network are extremely erratic and vary greatly from run to run (version 3 is significantly worse, for example). Version 7 scores 0.277!\n",
    "\n",
    "You should easily be able to stabilize and improve the results just by changing a few parameters, tweaking the architecture a little bit and training longer with early stopping.\n",
    "\n",
    "**Have fun!**\n",
    "\n",
    "LB score history:\n",
    "- Version 7: 0.277 LB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
